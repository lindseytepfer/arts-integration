{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e176ad1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "necessary installs: \n",
    "* whisperx\n",
    "* transformers\n",
    "* datawrangler\n",
    "* https://huggingface.co/roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2258144",
   "metadata": {},
   "source": [
    "# 1. Converting speech audio data to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5a67ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 00:42:57.209603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "objc[45032]: Class AVFFrameReceiver is implemented in both /Users/f004p74/anaconda3/lib/libavdevice.58.10.100.dylib (0x123afc078) and /Users/f004p74/anaconda3/lib/python3.9/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x13a86f118). One of the two will be used. Which one is undefined.\n",
      "objc[45032]: Class AVFAudioReceiver is implemented in both /Users/f004p74/anaconda3/lib/libavdevice.58.10.100.dylib (0x123afc0c8) and /Users/f004p74/anaconda3/lib/python3.9/site-packages/av/.dylibs/libavdevice.59.7.100.dylib (0x13a86f168). One of the two will be used. Which one is undefined.\n",
      "/Users/f004p74/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/f004p74/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowExxb\n",
      "  Referenced from: <AE5A0901-5B6C-3028-ADEE-0C068D0474D9> /Users/f004p74/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <22270481-544D-33A2-9FD1-270293676910> /Users/f004p74/anaconda3/lib/python3.9/site-packages/torch/lib/libc10.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454fb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" # default is cuda\n",
    "batch_size = 16 # reduce if low on GPU mem    \n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3609786",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/path/to/audio/segments/files/\"\n",
    "transcribed_path = 'convo_art/transcripts/'\n",
    "\n",
    "file_list = glob(os.path.join(audio_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_file in file_list:\n",
    "\n",
    "    #Unaligned transcriptions\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "    result = model.transcribe(audio, batch_size=batch_size)\n",
    "    \n",
    "    #Aligned transcriptions\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "    result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "    \n",
    "    with open(audio_track+\".json\",\"w\") as write_file:\n",
    "        json.dump(result[\"segments\"],write_file)\n",
    "    \n",
    "    subprocess.run([\"-mv\", \"audio_path+audio_file\", \"/path/to/audio/segments/text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb4674",
   "metadata": {},
   "source": [
    "# 2. Taking in text segments and generating Embeddings using RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab1a1608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawrangler as dw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "077ec474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to check if this actually ports in roBERTa\n",
    "roberta = {'model': 'TransformerDocumentEmbeddings', 'args': ['roberta-base'], 'kwargs': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d68e48c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " 'index-ceres.js',\n",
       " 'cTom-testing',\n",
       " 'personal-site',\n",
       " 'cTom-experiment']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/f004p74/Documents/dartmouth/projects/arts-integration/transcripts/'\n",
    "out_dir = os.listdir(path)\n",
    "dirlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3df605fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = os.listdir(path)\n",
    "transcripts = [x for x in out_dir if '.json' in x]\n",
    "\n",
    "segment, start, end = [], [], [] \n",
    "\n",
    "for file in transcripts:\n",
    "    with open(path+os.sep+file, \"r\") as read_file:\n",
    "        data = json.load(read_file)\n",
    "\n",
    "    for line in range(len(data)):\n",
    "        segment.append(data[line][\"text\"])\n",
    "        start.append(data[line][\"start\"])\n",
    "        end.append(data[line][\"end\"])\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for i in segment[0:2]:\n",
    "    bert_embeddings = dw.wrangle(i, text_kwargs={'model': roberta})\n",
    "    embeddings.append(bert_embeddings)\n",
    "\n",
    "df = pd.concat(embeddings)\n",
    "df[\"start\"] = start[0:2]\n",
    "df[\"end\"] = end[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32405578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.026634</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>-0.040498</td>\n",
       "      <td>-0.105231</td>\n",
       "      <td>0.068990</td>\n",
       "      <td>-0.083818</td>\n",
       "      <td>-0.017453</td>\n",
       "      <td>0.022588</td>\n",
       "      <td>0.086036</td>\n",
       "      <td>-0.106865</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036755</td>\n",
       "      <td>-0.065474</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.133913</td>\n",
       "      <td>0.101147</td>\n",
       "      <td>-0.047516</td>\n",
       "      <td>-0.050494</td>\n",
       "      <td>0.014184</td>\n",
       "      <td>0.789</td>\n",
       "      <td>9.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049831</td>\n",
       "      <td>0.048819</td>\n",
       "      <td>-0.050759</td>\n",
       "      <td>-0.133401</td>\n",
       "      <td>0.072044</td>\n",
       "      <td>-0.062051</td>\n",
       "      <td>-0.009552</td>\n",
       "      <td>-0.036435</td>\n",
       "      <td>0.076738</td>\n",
       "      <td>-0.095187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053567</td>\n",
       "      <td>-0.081428</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>0.100437</td>\n",
       "      <td>0.131865</td>\n",
       "      <td>-0.090388</td>\n",
       "      <td>-0.058640</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>9.501</td>\n",
       "      <td>15.689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.026634  0.085026 -0.040498 -0.105231  0.068990 -0.083818 -0.017453   \n",
       "0 -0.049831  0.048819 -0.050759 -0.133401  0.072044 -0.062051 -0.009552   \n",
       "\n",
       "          7         8         9  ...       760       761       762       763  \\\n",
       "0  0.022588  0.086036 -0.106865  ... -0.036755 -0.065474 -0.000728  0.133913   \n",
       "0 -0.036435  0.076738 -0.095187  ... -0.053567 -0.081428 -0.006288  0.100437   \n",
       "\n",
       "        764       765       766       767  start     end  \n",
       "0  0.101147 -0.047516 -0.050494  0.014184  0.789   9.501  \n",
       "0  0.131865 -0.090388 -0.058640  0.015110  9.501  15.689  \n",
       "\n",
       "[2 rows x 770 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19f707c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_transcripts (path):\n",
    "    out_dir = os.listdir(path)\n",
    "    transcripts = [x for x in out_dir if '.json' in x]\n",
    "\n",
    "    segment, start, end = [], [], [] \n",
    "\n",
    "    for file in transcripts:\n",
    "        with open(path+os.sep+file, \"r\") as read_file:\n",
    "            data = json.load(read_file)\n",
    "\n",
    "        for line in range(len(data)):\n",
    "            segment.append(data[line][\"text\"])\n",
    "            start.append(data[line][\"start\"])\n",
    "            end.append(data[line][\"end\"])\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for i in segment:\n",
    "        bert_embeddings = dw.wrangle(i, text_kwargs={'model': roberta})\n",
    "        embeddings.append(bert_embeddings)\n",
    "\n",
    "    df = pd.concat(embeddings)\n",
    "    df[\"start\"] = start\n",
    "    df[\"end\"] = end\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fdb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_transcripts('/Users/f004p74/Documents/dartmouth/projects/arts-integration/transcripts/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b544d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57764b30",
   "metadata": {},
   "source": [
    "# 3. Taking cosine distance of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_convos = pd.read_csv('')\n",
    "\n",
    "for ix in range(embeddings.index.max()+1):\n",
    "    distance_list = []\n",
    "    #past embeddings vs current track's embeddings(bert_embeddings)\n",
    "    distance_list.append(distance.cosine(previous_convos.loc[ix,3:724],bert_embeddings))\n",
    "    \n",
    "previous_convos['distances'] = distance_list\n",
    "\n",
    "previous_convos.sort_values(by=['distances'], ascending=True, inplace=True)\n",
    "top_5 = previous_convos[0:4,['tracks']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efdd2ad",
   "metadata": {},
   "source": [
    "# 4. Making a UMAP of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36815aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b63c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(filepath+\"full_dataset.csv\")\n",
    "features = dataset.loc[:,:\"767\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57152c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap2d = UMAP(n_components=2, n_neighbors=30, init='random',random_state=0, metric='cosine')\n",
    "\n",
    "proj_2d = umap2d.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d = pd.DataFrame(proj_2d)\n",
    "df2d[[\"start\",\"end\",\"episode\",\"segment\"]] = dataset[[\"start\",\"end\",\"episode\",\"segment\"]]\n",
    "\n",
    "fig2d = px.scatter(proj_2d, x=0, y=1, color=df2d.start, labels={'color':'start'})\n",
    "fig2d.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
