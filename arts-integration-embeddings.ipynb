{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e176ad1",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "necessary installs: \n",
    "* whisperx\n",
    "* transformers\n",
    "* datawrangler\n",
    "* https://huggingface.co/roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2258144",
   "metadata": {},
   "source": [
    "# 1. Converting speech audio data to text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454fb886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "from scipy.spatial import distance\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9426705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" # default is cuda\n",
    "batch_size = 16 # reduce if low on GPU mem    \n",
    "compute_type = \"float16\" # change to \"int8\" if low on GPU mem (may reduce accuracy)\n",
    "\n",
    "model = whisperx.load_model(\"large-v2\", device, compute_type=compute_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3609786",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"/path/to/audio/segments/files/\"\n",
    "transcribed_path = '/path/to/audio/segments/text/'\n",
    "\n",
    "file_list = glob(os.path.join(audio_path, '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdd3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_file in file_list:\n",
    "\n",
    "    #Unaligned transcriptions\n",
    "    audio = whisperx.load_audio(audio_file)\n",
    "    result = model.transcribe(audio, batch_size=batch_size)\n",
    "    \n",
    "    #Aligned transcriptions\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n",
    "    result = whisperx.align(result[\"segments\"], model_a, metadata, audio, device, return_char_alignments=False)\n",
    "    \n",
    "    with open(audio_track+\".json\",\"w\") as write_file:\n",
    "        json.dump(result[\"segments\"],write_file)\n",
    "    \n",
    "    subprocess.run([\"-mv\", \"audio_path+audio_file\", \"/path/to/audio/segments/text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedb4674",
   "metadata": {},
   "source": [
    "# 2. Taking in text segments and generating Embeddings using RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077ec474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datawrangler as dw \n",
    "\n",
    "#need to check if this actually ports in roBERTa\n",
    "roberta = {'model': 'TransformerDocumentEmbeddings', 'args': ['roberta-base'], 'kwargs': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f707c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for track,whisper_data in enumerate(json_dicts):\n",
    "    whisper_segments, start_times, end_times = [], [], [] \n",
    "    \n",
    "    for segment in range(len(whisper_data)):\n",
    "        whisper_segments.append(whisper_data[segment][\"text\"])\n",
    "        start_times.append(whisper_data[segment][\"start\"])\n",
    "        end_times.append(whisper_data[segment][\"end\"])\n",
    "        \n",
    "    embeddings = pd.DataFrame()\n",
    "    \n",
    "    for segment in whisper_segments:\n",
    "        bert_embeddings = dw.wrangle(segment, text_kwargs={'model': roberta})\n",
    "        embeddings = embeddings.append(bert_embeddings, ignore_index = True)\n",
    "    \n",
    "    embeddings[\"start\"] = start_times\n",
    "    embeddings[\"end\"] = end_times\n",
    "    \n",
    "    embeddings.to_csv(json_files[track]+\"_embeddings.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57764b30",
   "metadata": {},
   "source": [
    "# 3. Taking cosine distance of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173cee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_convos = pd.read_csv('')\n",
    "\n",
    "for ix in range(embeddings.index.max()+1):\n",
    "    distance_list = []\n",
    "    #past embeddings vs current track's embeddings(bert_embeddings)\n",
    "    distance_list.append(distance.cosine(previous_convos.loc[ix,3:724],bert_embeddings))\n",
    "    \n",
    "previous_convos['distances'] = distance_list\n",
    "\n",
    "previous_convos.sort_values(by=['distances'], ascending=True, inplace=True)\n",
    "top_5 = previous_convos[0:4,['tracks']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efdd2ad",
   "metadata": {},
   "source": [
    "# 4. Making a UMAP of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36815aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b63c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(filepath+\"full_dataset.csv\")\n",
    "features = dataset.loc[:,:\"767\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57152c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap2d = UMAP(n_components=2, n_neighbors=30, init='random',random_state=0, metric='cosine')\n",
    "\n",
    "proj_2d = umap2d.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338b8bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2d = pd.DataFrame(proj_2d)\n",
    "df2d[[\"start\",\"end\",\"episode\",\"segment\"]] = dataset[[\"start\",\"end\",\"episode\",\"segment\"]]\n",
    "\n",
    "fig2d = px.scatter(proj_2d, x=0, y=1, color=df2d.start, labels={'color':'start'})\n",
    "fig2d.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
